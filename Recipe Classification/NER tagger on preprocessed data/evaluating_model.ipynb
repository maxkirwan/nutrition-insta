{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c3ea556",
   "metadata": {},
   "source": [
    "# Evaluating custom NER model\n",
    "Now that I have built a custom NER model and tried it out on some unseen text, I want to compute some evaluation metrics to see exactly how the model performs.\n",
    "\n",
    "## First need to produce an annotated test set (unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29c3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81144d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load in json file from LightTag\n",
    "def load_json_to_df(file):\n",
    "    \n",
    "    results = json.load(open(file))\n",
    "    \n",
    "    # Create list of only those posts which have been annotated\n",
    "    annotated = []\n",
    "    for example in results['examples']:\n",
    "        if example['annotations'] != []:\n",
    "            annotated.append(example)\n",
    "            \n",
    "    return pd.DataFrame(annotated)\n",
    "\n",
    "\n",
    "# Function to convert data into spacy format\n",
    "def convert_to_spacy_format(df):\n",
    "    \n",
    "    TRAIN_DATA = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        sentence = row['content']\n",
    "        annotations_input_list = row['annotations']\n",
    "        \n",
    "        annotations_output_list = []\n",
    "        ing_dict = {}\n",
    "        \n",
    "        for annotation in annotations_input_list:\n",
    "            \n",
    "            annotations_output_list.append((annotation['start'], annotation['end'], annotation['tag']))\n",
    "        \n",
    "        ing_dict['entities'] = annotations_output_list\n",
    "        TRAIN_DATA.append((sentence, ing_dict))\n",
    "        \n",
    "    return TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229c31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = convert_to_spacy_format(load_json_to_df('ingredient-tagger_annotations.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4de78e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for post, entities in TRAIN_DATA:\n",
    "    if 'hearty zesty treat' in post:\n",
    "        print(post)\n",
    "        print(\"\\n-------\\n\")\n",
    "        print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a571b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = convert_to_spacy_format(load_json_to_df('ingredient-tagger_annotations_2.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcc18e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = []\n",
    "for post, entities in TEST_DATA:\n",
    "    if post not in [TRAIN_DATA[i][0] for i in range(len(TRAIN_DATA))]:\n",
    "        test_set.append((post, entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c59089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09326b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 14/14 [00:00<00:00, 104.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (136, 143, 'INGREDIENT')\n",
      "Skipping entity: (103, 109, 'INGREDIENT')\n",
      "Skipping entity: (122, 126, 'INGREDIENT')\n",
      "Skipping entity: (70, 71, 'QUANTITY')\n",
      "Skipping entity: (128, 134, 'INGREDIENT')\n",
      "Skipping entity: (82, 83, 'QUANTITY')\n",
      "[2, 45, ham, potatoes, 5, oil, potato, 1]\n",
      "[red onion, cup, tomatoes, 1, 1 /2, 2, cup, grape, honey, lime juice, cup, 1/4, 1/2, black pepper, basil, 1, watermelon, 5, 1, tb, cup]\n",
      "[basil, olive oil, basil, pasta, mozzarella, pasta, vinegar, chicken, tomatoes, sausage]\n",
      "[cream, dash, water, cup, 1/2, 1, 1, chia seeds, 3, vanilla protein powder, cup, oats, vanilla, egg white, teaspoon, egg, 1, 5, banana, 1/2, tablespoon, 1]\n",
      "Error with document\n",
      "[ml, 1, 2, 2, 70, 10, 4, flour, 3, eggs, self-raising flour, 5, cup, cup, cup, oranges, teaspoon, 2, 6, sugar, 4, oil, eggs, baking powder, orange juice, 2, oil, cup, sugar, 1, 1, half, sugar, cup, orange juice, half, baking powder, 8, 1, flour]\n",
      "Error with document\n",
      "Skipping entity: (307, 309, 'QUANTITY')\n",
      "[cream cheese, cream cheese, butter, carrots, sandwich thins, avocado, bagel, carrot, carrot]\n",
      "[mozzarella, 2, marinara, mozzarella, marinara, tortilla, 3, 2, 1, pepperoni, pepperoni]\n",
      "Skipping entity: (1725, 1730, 'INGREDIENT')\n",
      "Skipping entity: (1731, 1736, 'INGREDIENT')\n",
      "Skipping entity: (1737, 1744, 'INGREDIENT')\n",
      "[1, pound, tablespoon, 1, chicken breast, teaspoon, salt, 6, pasta, 3, lemon, noodles, 2, noodles, package, chicken, chicken, teaspoon, 1, 2, 1/2, tablespoon, lemon, 5, 2, butter, salt, chicken, oregano, oregano, butter, chicken, 1, oil, teaspoon, 4, collagelatin, 1, tablespoon, chicken, clove, oregano, noodles, lemon, 2, 3, ghee, 10, 1, 2, oil, 1/2, noodles, 1, oil, tablespoon, lemon, oregano, chicken, 15, oregano, pasta, 8, oil, 1, lemon juice, lemon, package, garlic, 1, water, noodles, garlic, 200]\n",
      "Skipping entity: (1028, 1029, 'QUANTITY')\n",
      "Skipping entity: (1006, 1007, 'QUANTITY')\n",
      "Skipping entity: (1041, 1042, 'QUANTITY')\n",
      "Skipping entity: (994, 995, 'QUANTITY')\n",
      "Skipping entity: (1026, 1027, 'QUANTITY')\n",
      "[onion, gram, 2, gram, pumpkin, pumpkin, olive oil, pumpkin, spices, gram, 100, pumpkin, onion, water, 8, olive oil, salt, 10, olive oil, 50, 3, pumpkin, 4, 1, water, gram, gram, 10, pumpkin, garlic, 2, 15, pumpkin, 30, 1, pepper, gram, 3, 30, pumpkin, 200, 6, 5, 200, garlic, chickpeas, pumpkin, pumpkin, pumpkin, olive oil, 125, pumpkin]\n",
      "[salt, oil, tablespoon, cumin, garam masala, garlic, 2, cup, spices, gram, ghee, cream, teaspoon, 50, paneer, 2, gram, cumin, mawa, pepper, ghee, cinnamon, tablespoon, 15, onion, milk, garlic, 1, cashews, 1, paneer, garam masala, cardamom, 4, cinnamon, yogurt, 1/2, salt, yogurt, oil, cashews, cream, milk, 1, 250, clove, tablespoon, 100, milk, 4, 1, clove, 1, 4, 3, 2, cinnamon, water, 1, teaspoon, 1/2, cup, 8, 1, 5, 3, gram, clove, 2, onion, 2, tej patta, 1, paneer]\n",
      "[200, snickers, cream, almond butter, gram, cacao, gram, flour, gram, tofu, zucchini, blackberries, gram, 200, chia seeds, banana]\n",
      "[baking soda, baking powder, 1, 1/2, coconut oil, 1/2, pistachio, vanilla extract, 3, 1/4, 1/2, 1/4, cup, cup, teaspoon, almond, tablespoon, salt, eggs, 1/2, cup, coffee, oil, teaspoon, 1, 1/2, 1/4, 2, 1, 1, chocolate chips, cup, teaspoon, 3, sugar, pistachio, 1, 1, flour, 1/4, 1/2, 1, cup, cinnamon, 1, teaspoon, oil, 30, 1/2, 1/2, cup, almond, teaspoon, 2, 10]\n",
      "Error with document\n",
      "[black pepper, butter, paneer, paneer, aaloo, chaat masala, salt, flour, soybean, jeera powder, red chilli powder, hing, onion, chilli, garam masala, achaar, oil]\n",
      "[red chilli powder, chat masala, coriender, 1/2, egg, eggs, egg, ajwain, teaspoon, salt, egg, cup, water, pinch, besan, 1/2, jeera, turmeric, teaspoon, oil, eggs, 1/2]\n"
     ]
    }
   ],
   "source": [
    "# Converting test_set to docbin spacy file\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_to_spacy_docbin(dataset, file_location):\n",
    "    \n",
    "    nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "    db = DocBin() # create a DocBin object\n",
    "\n",
    "    for text, annot in tqdm(dataset):\n",
    "        doc = nlp.make_doc(text) \n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(f\"Skipping entity: {(start,end,label)}\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        print(ents)\n",
    "        try:\n",
    "            doc.ents = ents\n",
    "        except:\n",
    "            print(f\"Error with document\")\n",
    "        db.add(doc)\n",
    "\n",
    "    db.to_disk(file_location) # save the docbin object\n",
    "\n",
    "\n",
    "convert_to_spacy_docbin(test_set, \"./test.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def61c47",
   "metadata": {},
   "source": [
    "## Now time to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa9fd2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   85.21 \n",
      "NER R   77.07 \n",
      "NER F   80.94 \n",
      "SPEED   12296 \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                  P       R       F\n",
      "INGREDIENT    78.85   68.72   73.43\n",
      "QUANTITY      92.94   85.87   89.27\n",
      "MEASUREMENT   93.02   93.02   93.02\n",
      "\n",
      "\u001b[38;5;2m✔ Saved results to evaluation_metrics.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy evaluate ./model-best ./test.spacy --output ./evaluation_metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a085167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_acc': 1.0,\n",
       " 'token_p': 1.0,\n",
       " 'token_r': 1.0,\n",
       " 'token_f': 1.0,\n",
       " 'ents_p': 0.8521126761,\n",
       " 'ents_r': 0.7707006369,\n",
       " 'ents_f': 0.8093645485,\n",
       " 'ents_per_type': {'INGREDIENT': {'p': 0.7884615385,\n",
       "   'r': 0.687150838,\n",
       "   'f': 0.7343283582},\n",
       "  'QUANTITY': {'p': 0.9294117647, 'r': 0.8586956522, 'f': 0.8926553672},\n",
       "  'MEASUREMENT': {'p': 0.9302325581, 'r': 0.9302325581, 'f': 0.9302325581}},\n",
       " 'speed': 12295.7972191879}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open(\"evaluation_metrics.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1517197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   85.21 \n",
      "NER R   77.07 \n",
      "NER F   80.94 \n",
      "SPEED   12622 \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                  P       R       F\n",
      "INGREDIENT    78.85   68.72   73.43\n",
      "QUANTITY      92.94   85.87   89.27\n",
      "MEASUREMENT   93.02   93.02   93.02\n",
      "\n",
      "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy evaluate ./model-best ./test.spacy -dp ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729df2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
